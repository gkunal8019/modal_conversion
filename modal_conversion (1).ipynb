{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f696df-3e21-44a4-bef2-5f26041b6ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6.25M/6.25M [00:00<00:00, 23.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ‚ö†Ô∏è TensorRT requires GPU export, automatically assigning device=0\n",
      "Ultralytics YOLOv8.2.100 üöÄ Python-3.10.12 torch-2.4.1+cu121 CUDA:0 (Tesla V100-PCIE-16GB, 16144MiB)\n",
      "YOLOv8n summary (fused): 168 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov8n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime-gpu'] not found, attempting AutoUpdate...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime-gpu\n",
      "  Downloading onnxruntime_gpu-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.3.25)\n",
      "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.23.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.1)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (4.25.5)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.13.3)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime-gpu) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\n",
      "Downloading onnxruntime_gpu-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (226.2 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m226.2/226.2 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: onnxruntime-gpu\n",
      "Successfully installed onnxruntime-gpu-1.19.2\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ‚úÖ 11.8s, installed 1 package: ['onnxruntime-gpu']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ‚ö†Ô∏è \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.2 opset 19...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.34...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success ‚úÖ 13.3s, saved as 'yolov8n.onnx' (12.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m starting export with TensorRT 10.3.0...\n",
      "[09/24/2024-12:38:48] [TRT] [I] [MemUsageChange] Init CUDA: CPU +2, GPU +0, now: CPU 569, GPU 11346 (MiB)\n",
      "[09/24/2024-12:38:49] [TRT] [I] [MemUsageChange] Init builder kernel library: CPU +440, GPU +78, now: CPU 1165, GPU 11424 (MiB)\n",
      "[09/24/2024-12:38:49] [TRT] [I] ----------------------------------------------------------------\n",
      "[09/24/2024-12:38:49] [TRT] [I] Input filename:   yolov8n.onnx\n",
      "[09/24/2024-12:38:49] [TRT] [I] ONNX IR version:  0.0.10\n",
      "[09/24/2024-12:38:49] [TRT] [I] Opset version:    19\n",
      "[09/24/2024-12:38:49] [TRT] [I] Producer name:    pytorch\n",
      "[09/24/2024-12:38:49] [TRT] [I] Producer version: 2.4.1\n",
      "[09/24/2024-12:38:49] [TRT] [I] Domain:           \n",
      "[09/24/2024-12:38:49] [TRT] [I] Model version:    0\n",
      "[09/24/2024-12:38:49] [TRT] [I] Doc string:       \n",
      "[09/24/2024-12:38:49] [TRT] [I] ----------------------------------------------------------------\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m input \"images\" with shape(1, 3, 640, 640) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m output \"output0\" with shape(1, 84, 8400) DataType.FLOAT\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m building FP32 engine as yolov8n.engine\n",
      "[09/24/2024-12:38:49] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
      "[09/24/2024-12:38:49] [TRT] [I] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
      "[09/24/2024-12:38:49] [TRT] [I] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[09/24/2024-12:40:23] [TRT] [I] Detected 1 inputs and 3 output network tensors.\n",
      "[09/24/2024-12:40:23] [TRT] [I] Total Host Persistent Memory: 294080\n",
      "[09/24/2024-12:40:23] [TRT] [I] Total Device Persistent Memory: 259584\n",
      "[09/24/2024-12:40:23] [TRT] [I] Total Scratch Memory: 1639424\n",
      "[09/24/2024-12:40:23] [TRT] [I] [BlockAssignment] Started assigning block shifts. This will take 228 steps to complete.\n",
      "[09/24/2024-12:40:23] [TRT] [I] [BlockAssignment] Algorithm ShiftNTopDown took 19.9292ms to assign 8 blocks to 228 nodes requiring 20480512 bytes.\n",
      "[09/24/2024-12:40:23] [TRT] [I] Total Activation Memory: 20480000\n",
      "[09/24/2024-12:40:23] [TRT] [I] Total Weights Memory: 15585796\n",
      "[09/24/2024-12:40:23] [TRT] [I] Engine generation completed in 94.0752 seconds.\n",
      "[09/24/2024-12:40:23] [TRT] [I] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 1 MiB, GPU 261 MiB\n",
      "[09/24/2024-12:40:23] [TRT] [I] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 1997 MiB\n",
      "\u001b[34m\u001b[1mTensorRT:\u001b[0m export success ‚úÖ 109.2s, saved as 'yolov8n.engine' (16.2 MB)\n",
      "\n",
      "Export complete (110.2s)\n",
      "Results saved to \u001b[1m/env/kunal/tensor-rt\u001b[0m\n",
      "Predict:         yolo predict task=detect model=yolov8n.engine imgsz=640  \n",
      "Validate:        yolo val task=detect model=yolov8n.engine imgsz=640 data=coco.yaml  \n",
      "Visualize:       https://netron.app\n",
      "WARNING ‚ö†Ô∏è Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Loading yolov8n.engine for TensorRT inference...\n",
      "[09/24/2024-12:40:24] [TRT] [I] Loaded engine size: 16 MiB\n",
      "[09/24/2024-12:40:24] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +19, now: CPU 0, GPU 34 (MiB)\n",
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 134k/134k [00:00<00:00, 1.60MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 /env/kunal/tensor-rt/bus.jpg: 640x640 4 persons, 1 bus, 2.5ms\n",
      "Speed: 7.8ms preprocess, 2.5ms inference, 154.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# Export the model to TensorRT format\n",
    "model.export(format=\"engine\")  # creates 'yolov8n.engine'\n",
    "\n",
    "# Load the exported TensorRT model\n",
    "tensorrt_model = YOLO(\"yolov8n.engine\")\n",
    "\n",
    "# Run inference\n",
    "results = tensorrt_model(\"https://ultralytics.com/images/bus.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f8f9518-a5a0-42f5-b3e8-37a5c8c5239a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "Package python is not available, but is referred to by another package.\n",
      "This may mean that the package is missing, has been obsoleted, or\n",
      "is only available from another source\n",
      "However the following packages replace it:\n",
      "  2to3 python2-minimal python2 dh-python python-is-python3\n",
      "\n",
      "\u001b[1;31mE: \u001b[0mPackage 'python' has no installation candidate\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!apt install python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dd48c83-5a1f-44f6-b187-aebbdb8e4083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx-simplifier\n",
      "  Downloading onnx_simplifier-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from onnx-simplifier) (1.16.2)\n",
      "Collecting rich (from onnx-simplifier)\n",
      "  Downloading rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx-simplifier) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->onnx-simplifier) (4.25.5)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->onnx-simplifier)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->onnx-simplifier) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->onnx-simplifier)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading onnx_simplifier-0.4.36-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: mdurl, markdown-it-py, rich, onnx-simplifier\n",
      "Successfully installed markdown-it-py-3.0.0 mdurl-0.1.2 onnx-simplifier-0.4.36 rich-13.8.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install onnx-simplifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc5ecaeb-b461-4c9d-b709-2993750100e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplifying\u001b[33m...\u001b[0m\n",
      "Finish! Here is the difference:\n",
      "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
      "‚îÉ\u001b[1m \u001b[0m\u001b[1m          \u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mOriginal Model\u001b[0m\u001b[1m \u001b[0m‚îÉ\u001b[1m \u001b[0m\u001b[1mSimplified Model\u001b[0m\u001b[1m \u001b[0m‚îÉ\n",
      "‚î°‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©\n",
      "‚îÇ Add        ‚îÇ 8              ‚îÇ 8                ‚îÇ\n",
      "‚îÇ Concat     ‚îÇ 19             ‚îÇ 19               ‚îÇ\n",
      "‚îÇ Constant   ‚îÇ 144            ‚îÇ \u001b[1;32m143             \u001b[0m ‚îÇ\n",
      "‚îÇ Conv       ‚îÇ 64             ‚îÇ 64               ‚îÇ\n",
      "‚îÇ Div        ‚îÇ 1              ‚îÇ 1                ‚îÇ\n",
      "‚îÇ MaxPool    ‚îÇ 3              ‚îÇ 3                ‚îÇ\n",
      "‚îÇ Mul        ‚îÇ 58             ‚îÇ 58               ‚îÇ\n",
      "‚îÇ Reshape    ‚îÇ 5              ‚îÇ 5                ‚îÇ\n",
      "‚îÇ Resize     ‚îÇ 2              ‚îÇ 2                ‚îÇ\n",
      "‚îÇ Sigmoid    ‚îÇ 58             ‚îÇ 58               ‚îÇ\n",
      "‚îÇ Slice      ‚îÇ 2              ‚îÇ 2                ‚îÇ\n",
      "‚îÇ Softmax    ‚îÇ 1              ‚îÇ 1                ‚îÇ\n",
      "‚îÇ Split      ‚îÇ 9              ‚îÇ 9                ‚îÇ\n",
      "‚îÇ Sub        ‚îÇ 2              ‚îÇ 2                ‚îÇ\n",
      "‚îÇ Transpose  ‚îÇ 1              ‚îÇ 1                ‚îÇ\n",
      "‚îÇ Model Size ‚îÇ 12.2MiB        ‚îÇ \u001b[1;32m12.2MiB         \u001b[0m ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "!python3 -m onnxsim yolov8n.onnx yolo_simplified.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87cd86a4-8a3f-4740-80f3-4a6221e94b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "&&&& RUNNING TensorRT.trtexec [TensorRT v100300] # trtexec --onnx=yolo_simplified.onnx --saveEngine=yolo.trt --fp16\n",
      "[09/24/2024-12:52:09] [I] === Model Options ===\n",
      "[09/24/2024-12:52:09] [I] Format: ONNX\n",
      "[09/24/2024-12:52:09] [I] Model: yolo_simplified.onnx\n",
      "[09/24/2024-12:52:09] [I] Output:\n",
      "[09/24/2024-12:52:09] [I] === Build Options ===\n",
      "[09/24/2024-12:52:09] [I] Memory Pools: workspace: default, dlaSRAM: default, dlaLocalDRAM: default, dlaGlobalDRAM: default, tacticSharedMem: default\n",
      "[09/24/2024-12:52:09] [I] avgTiming: 8\n",
      "[09/24/2024-12:52:09] [I] Precision: FP32+FP16\n",
      "[09/24/2024-12:52:09] [I] LayerPrecisions: \n",
      "[09/24/2024-12:52:09] [I] Layer Device Types: \n",
      "[09/24/2024-12:52:09] [I] Calibration: \n",
      "[09/24/2024-12:52:09] [I] Refit: Disabled\n",
      "[09/24/2024-12:52:09] [I] Strip weights: Disabled\n",
      "[09/24/2024-12:52:09] [I] Version Compatible: Disabled\n",
      "[09/24/2024-12:52:09] [I] ONNX Plugin InstanceNorm: Disabled\n",
      "[09/24/2024-12:52:09] [I] TensorRT runtime: full\n",
      "[09/24/2024-12:52:09] [I] Lean DLL Path: \n",
      "[09/24/2024-12:52:09] [I] Tempfile Controls: { in_memory: allow, temporary: allow }\n",
      "[09/24/2024-12:52:09] [I] Exclude Lean Runtime: Disabled\n",
      "[09/24/2024-12:52:09] [I] Sparsity: Disabled\n",
      "[09/24/2024-12:52:09] [I] Safe mode: Disabled\n",
      "[09/24/2024-12:52:09] [I] Build DLA standalone loadable: Disabled\n",
      "[09/24/2024-12:52:09] [I] Allow GPU fallback for DLA: Disabled\n",
      "[09/24/2024-12:52:09] [I] DirectIO mode: Disabled\n",
      "[09/24/2024-12:52:09] [I] Restricted mode: Disabled\n",
      "[09/24/2024-12:52:09] [I] Skip inference: Disabled\n",
      "[09/24/2024-12:52:09] [I] Save engine: yolo.trt\n",
      "[09/24/2024-12:52:09] [I] Load engine: \n",
      "[09/24/2024-12:52:09] [I] Profiling verbosity: 0\n",
      "[09/24/2024-12:52:09] [I] Tactic sources: Using default tactic sources\n",
      "[09/24/2024-12:52:09] [I] timingCacheMode: local\n",
      "[09/24/2024-12:52:09] [I] timingCacheFile: \n",
      "[09/24/2024-12:52:09] [I] Enable Compilation Cache: Enabled\n",
      "[09/24/2024-12:52:09] [I] errorOnTimingCacheMiss: Disabled\n",
      "[09/24/2024-12:52:09] [I] Preview Features: Use default preview flags.\n",
      "[09/24/2024-12:52:09] [I] MaxAuxStreams: -1\n",
      "[09/24/2024-12:52:09] [I] BuilderOptimizationLevel: -1\n",
      "[09/24/2024-12:52:09] [I] Calibration Profile Index: 0\n",
      "[09/24/2024-12:52:09] [I] Weight Streaming: Disabled\n",
      "[09/24/2024-12:52:09] [I] Runtime Platform: Same As Build\n",
      "[09/24/2024-12:52:09] [I] Debug Tensors: \n",
      "[09/24/2024-12:52:09] [I] Input(s)s format: fp32:CHW\n",
      "[09/24/2024-12:52:09] [I] Output(s)s format: fp32:CHW\n",
      "[09/24/2024-12:52:09] [I] Input build shapes: model\n",
      "[09/24/2024-12:52:09] [I] Input calibration shapes: model\n",
      "[09/24/2024-12:52:09] [I] === System Options ===\n",
      "[09/24/2024-12:52:09] [I] Device: 0\n",
      "[09/24/2024-12:52:09] [I] DLACore: \n",
      "[09/24/2024-12:52:09] [I] Plugins:\n",
      "[09/24/2024-12:52:09] [I] setPluginsToSerialize:\n",
      "[09/24/2024-12:52:09] [I] dynamicPlugins:\n",
      "[09/24/2024-12:52:09] [I] ignoreParsedPluginLibs: 0\n",
      "[09/24/2024-12:52:09] [I] \n",
      "[09/24/2024-12:52:09] [I] === Inference Options ===\n",
      "[09/24/2024-12:52:09] [I] Batch: Explicit\n",
      "[09/24/2024-12:52:09] [I] Input inference shapes: model\n",
      "[09/24/2024-12:52:09] [I] Iterations: 10\n",
      "[09/24/2024-12:52:09] [I] Duration: 3s (+ 200ms warm up)\n",
      "[09/24/2024-12:52:09] [I] Sleep time: 0ms\n",
      "[09/24/2024-12:52:09] [I] Idle time: 0ms\n",
      "[09/24/2024-12:52:09] [I] Inference Streams: 1\n",
      "[09/24/2024-12:52:09] [I] ExposeDMA: Disabled\n",
      "[09/24/2024-12:52:09] [I] Data transfers: Enabled\n",
      "[09/24/2024-12:52:09] [I] Spin-wait: Disabled\n",
      "[09/24/2024-12:52:09] [I] Multithreading: Disabled\n",
      "[09/24/2024-12:52:09] [I] CUDA Graph: Disabled\n",
      "[09/24/2024-12:52:09] [I] Separate profiling: Disabled\n",
      "[09/24/2024-12:52:09] [I] Time Deserialize: Disabled\n",
      "[09/24/2024-12:52:09] [I] Time Refit: Disabled\n",
      "[09/24/2024-12:52:09] [I] NVTX verbosity: 0\n",
      "[09/24/2024-12:52:09] [I] Persistent Cache Ratio: 0\n",
      "[09/24/2024-12:52:09] [I] Optimization Profile Index: 0\n",
      "[09/24/2024-12:52:09] [I] Weight Streaming Budget: 100.000000%\n",
      "[09/24/2024-12:52:09] [I] Inputs:\n",
      "[09/24/2024-12:52:09] [I] Debug Tensor Save Destinations:\n",
      "[09/24/2024-12:52:09] [I] === Reporting Options ===\n",
      "[09/24/2024-12:52:09] [I] Verbose: Disabled\n",
      "[09/24/2024-12:52:09] [I] Averages: 10 inferences\n",
      "[09/24/2024-12:52:09] [I] Percentiles: 90,95,99\n",
      "[09/24/2024-12:52:09] [I] Dump refittable layers:Disabled\n",
      "[09/24/2024-12:52:09] [I] Dump output: Disabled\n",
      "[09/24/2024-12:52:09] [I] Profile: Disabled\n",
      "[09/24/2024-12:52:09] [I] Export timing to JSON file: \n",
      "[09/24/2024-12:52:09] [I] Export output to JSON file: \n",
      "[09/24/2024-12:52:09] [I] Export profile to JSON file: \n",
      "[09/24/2024-12:52:09] [I] \n",
      "[09/24/2024-12:52:09] [I] === Device Information ===\n",
      "[09/24/2024-12:52:09] [I] Available Devices: \n",
      "[09/24/2024-12:52:09] [I]   Device 0: \"Tesla V100-PCIE-16GB\" UUID: GPU-273bc2e6-42a8-3097-5123-24fdb20f34fb\n",
      "[09/24/2024-12:52:10] [I] Selected Device: Tesla V100-PCIE-16GB\n",
      "[09/24/2024-12:52:10] [I] Selected Device ID: 0\n",
      "[09/24/2024-12:52:10] [I] Selected Device UUID: GPU-273bc2e6-42a8-3097-5123-24fdb20f34fb\n",
      "[09/24/2024-12:52:10] [I] Compute Capability: 7.0\n",
      "[09/24/2024-12:52:10] [I] SMs: 80\n",
      "[09/24/2024-12:52:10] [I] Device Global Memory: 16144 MiB\n",
      "[09/24/2024-12:52:10] [I] Shared Memory per SM: 96 KiB\n",
      "[09/24/2024-12:52:10] [I] Memory Bus Width: 4096 bits (ECC enabled)\n",
      "[09/24/2024-12:52:10] [I] Application Compute Clock Rate: 1.38 GHz\n",
      "[09/24/2024-12:52:10] [I] Application Memory Clock Rate: 0.877 GHz\n",
      "[09/24/2024-12:52:10] [I] \n",
      "[09/24/2024-12:52:10] [I] Note: The application clock rates do not reflect the actual clock rates that the GPU is currently running at.\n",
      "[09/24/2024-12:52:10] [I] \n",
      "[09/24/2024-12:52:10] [I] TensorRT version: 10.3.0\n",
      "[09/24/2024-12:52:10] [I] Loading standard plugins\n",
      "[09/24/2024-12:52:10] [I] [TRT] [MemUsageChange] Init CUDA: CPU +1, GPU +0, now: CPU 19, GPU 2238 (MiB)\n",
      "[09/24/2024-12:52:11] [I] [TRT] [MemUsageChange] Init builder kernel library: CPU +441, GPU +80, now: CPU 616, GPU 2318 (MiB)\n",
      "[09/24/2024-12:52:11] [I] Start parsing network model.\n",
      "[09/24/2024-12:52:11] [I] [TRT] ----------------------------------------------------------------\n",
      "[09/24/2024-12:52:11] [I] [TRT] Input filename:   yolo_simplified.onnx\n",
      "[09/24/2024-12:52:11] [I] [TRT] ONNX IR version:  0.0.10\n",
      "[09/24/2024-12:52:11] [I] [TRT] Opset version:    19\n",
      "[09/24/2024-12:52:11] [I] [TRT] Producer name:    pytorch\n",
      "[09/24/2024-12:52:11] [I] [TRT] Producer version: 2.4.1\n",
      "[09/24/2024-12:52:11] [I] [TRT] Domain:           \n",
      "[09/24/2024-12:52:11] [I] [TRT] Model version:    0\n",
      "[09/24/2024-12:52:11] [I] [TRT] Doc string:       \n",
      "[09/24/2024-12:52:11] [I] [TRT] ----------------------------------------------------------------\n",
      "[09/24/2024-12:52:11] [I] Finished parsing network model. Parse time: 0.0447708\n",
      "[09/24/2024-12:52:11] [I] [TRT] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
      "[09/24/2024-12:52:11] [I] [TRT] BuilderFlag::kTF32 is set but hardware does not support TF32. Disabling TF32.\n",
      "[09/24/2024-12:52:11] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.\n",
      "[09/24/2024-12:57:07] [I] [TRT] Detected 1 inputs and 3 output network tensors.\n",
      "[09/24/2024-12:57:10] [I] [TRT] Total Host Persistent Memory: 337712\n",
      "[09/24/2024-12:57:10] [I] [TRT] Total Device Persistent Memory: 131072\n",
      "[09/24/2024-12:57:10] [I] [TRT] Total Scratch Memory: 0\n",
      "[09/24/2024-12:57:10] [I] [TRT] [BlockAssignment] Started assigning block shifts. This will take 125 steps to complete.\n",
      "[09/24/2024-12:57:10] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 9.99636ms to assign 9 blocks to 125 nodes requiring 14030336 bytes.\n",
      "[09/24/2024-12:57:10] [I] [TRT] Total Activation Memory: 14028800\n",
      "[09/24/2024-12:57:10] [I] [TRT] Total Weights Memory: 6540928\n",
      "[09/24/2024-12:57:10] [I] [TRT] Engine generation completed in 299.575 seconds.\n",
      "[09/24/2024-12:57:10] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 0 MiB, GPU 261 MiB\n",
      "[09/24/2024-12:57:11] [I] [TRT] [MemUsageStats] Peak memory usage during Engine building and serialization: CPU: 1594 MiB\n",
      "[09/24/2024-12:57:11] [I] Engine built in 299.666 sec.\n",
      "[09/24/2024-12:57:11] [I] Created engine with size: 7.73542 MiB\n",
      "[09/24/2024-12:57:11] [I] [TRT] Loaded engine size: 7 MiB\n",
      "[09/24/2024-12:57:11] [I] Engine deserialized in 0.0327732 sec.\n",
      "[09/24/2024-12:57:11] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +13, now: CPU 0, GPU 19 (MiB)\n",
      "[09/24/2024-12:57:11] [I] Setting persistentCacheLimit to 0 bytes.\n",
      "[09/24/2024-12:57:11] [I] Created execution context with device memory size: 13.3789 MiB\n",
      "[09/24/2024-12:57:11] [I] Using random values for input images\n",
      "[09/24/2024-12:57:11] [I] Input binding for images with dimensions 1x3x640x640 is created.\n",
      "[09/24/2024-12:57:11] [I] Output binding for output0 with dimensions 1x84x8400 is created.\n",
      "[09/24/2024-12:57:11] [I] Starting inference\n",
      "[09/24/2024-12:57:14] [I] Warmup completed 74 queries over 200 ms\n",
      "[09/24/2024-12:57:14] [I] Timing trace has 802 queries over 3.00927 s\n",
      "[09/24/2024-12:57:14] [I] \n",
      "[09/24/2024-12:57:14] [I] === Trace details ===\n",
      "[09/24/2024-12:57:14] [I] Trace averages of 10 runs:\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 3.51859 ms - Host latency: 4.18593 ms (enqueue 2.03968 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 3.5524 ms - Host latency: 4.22292 ms (enqueue 2.00989 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 3.56206 ms - Host latency: 4.23096 ms (enqueue 2.05522 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 3.5614 ms - Host latency: 4.22812 ms (enqueue 1.96948 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 3.58757 ms - Host latency: 4.25931 ms (enqueue 2.03082 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 3.58788 ms - Host latency: 4.25592 ms (enqueue 2.11183 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 3.5855 ms - Host latency: 4.25027 ms (enqueue 2.01932 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 4.84036 ms - Host latency: 5.50797 ms (enqueue 2.06943 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.18379 ms - Host latency: 6.85091 ms (enqueue 2.16911 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42684 ms - Host latency: 7.08967 ms (enqueue 2.0917 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42714 ms - Host latency: 7.09349 ms (enqueue 2.11779 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42824 ms - Host latency: 7.10057 ms (enqueue 2.11864 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.43004 ms - Host latency: 7.09623 ms (enqueue 2.15889 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.43123 ms - Host latency: 7.09828 ms (enqueue 2.10079 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42441 ms - Host latency: 7.08881 ms (enqueue 2.11691 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42308 ms - Host latency: 7.08151 ms (enqueue 1.94066 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42148 ms - Host latency: 7.08393 ms (enqueue 2.38469 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42324 ms - Host latency: 7.08774 ms (enqueue 2.23693 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42255 ms - Host latency: 7.0923 ms (enqueue 2.0301 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42328 ms - Host latency: 7.09191 ms (enqueue 2.16515 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.51343 ms - Host latency: 7.18093 ms (enqueue 2.18748 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42603 ms - Host latency: 7.09789 ms (enqueue 2.19027 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42258 ms - Host latency: 7.09329 ms (enqueue 2.08519 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.43075 ms - Host latency: 7.10294 ms (enqueue 2.07191 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42939 ms - Host latency: 7.10417 ms (enqueue 2.09266 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.4281 ms - Host latency: 7.09142 ms (enqueue 2.16715 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42804 ms - Host latency: 7.09275 ms (enqueue 2.07715 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.42494 ms - Host latency: 7.08765 ms (enqueue 2.06295 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.43532 ms - Host latency: 7.09965 ms (enqueue 2.07358 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.33383 ms - Host latency: 6.9984 ms (enqueue 2.0631 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.16311 ms - Host latency: 6.82803 ms (enqueue 2.0736 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 6.14064 ms - Host latency: 6.80481 ms (enqueue 2.15944 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 4.69125 ms - Host latency: 5.35848 ms (enqueue 2.05681 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 3.4333 ms - Host latency: 4.10276 ms (enqueue 2.01816 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 3.20549 ms - Host latency: 3.87136 ms (enqueue 1.92273 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.83616 ms - Host latency: 3.49573 ms (enqueue 1.78918 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.61289 ms - Host latency: 3.26594 ms (enqueue 1.49077 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.38435 ms - Host latency: 3.03413 ms (enqueue 1.38081 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.49426 ms - Host latency: 3.13867 ms (enqueue 1.83149 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.15007 ms - Host latency: 2.79553 ms (enqueue 1.38821 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.08784 ms - Host latency: 2.73281 ms (enqueue 1.30435 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.047 ms - Host latency: 2.68879 ms (enqueue 1.55317 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.04321 ms - Host latency: 2.68833 ms (enqueue 1.20586 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.03713 ms - Host latency: 2.67986 ms (enqueue 1.16538 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.03677 ms - Host latency: 2.68206 ms (enqueue 1.21738 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.04734 ms - Host latency: 2.69299 ms (enqueue 1.15659 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.05222 ms - Host latency: 2.69629 ms (enqueue 1.32681 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.05923 ms - Host latency: 2.70447 ms (enqueue 1.47209 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.05212 ms - Host latency: 2.69766 ms (enqueue 1.17666 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.06379 ms - Host latency: 2.70879 ms (enqueue 1.18672 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.09849 ms - Host latency: 2.74602 ms (enqueue 1.17727 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.11267 ms - Host latency: 2.75908 ms (enqueue 1.14502 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.10588 ms - Host latency: 2.75122 ms (enqueue 1.23381 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.07732 ms - Host latency: 2.7229 ms (enqueue 1.18347 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.04907 ms - Host latency: 2.69292 ms (enqueue 1.19202 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.04956 ms - Host latency: 2.68757 ms (enqueue 1.11462 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.05012 ms - Host latency: 2.69226 ms (enqueue 1.48328 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.06316 ms - Host latency: 2.70571 ms (enqueue 1.38877 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.13098 ms - Host latency: 2.77451 ms (enqueue 1.17544 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.32646 ms - Host latency: 2.97344 ms (enqueue 1.29692 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.34949 ms - Host latency: 2.99836 ms (enqueue 1.31287 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.45039 ms - Host latency: 3.09888 ms (enqueue 1.33059 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.44609 ms - Host latency: 3.095 ms (enqueue 1.64202 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.42124 ms - Host latency: 3.06609 ms (enqueue 1.78105 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.4031 ms - Host latency: 3.04995 ms (enqueue 1.39839 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.39939 ms - Host latency: 3.05071 ms (enqueue 1.38479 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.4033 ms - Host latency: 3.05051 ms (enqueue 1.28071 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.40303 ms - Host latency: 3.05347 ms (enqueue 1.39734 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.41094 ms - Host latency: 3.05562 ms (enqueue 1.78953 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.40991 ms - Host latency: 3.05786 ms (enqueue 1.51677 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.4459 ms - Host latency: 3.09541 ms (enqueue 1.48877 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.44963 ms - Host latency: 3.09932 ms (enqueue 1.48037 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.45522 ms - Host latency: 3.10366 ms (enqueue 1.60264 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.44607 ms - Host latency: 3.09636 ms (enqueue 1.40947 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.42515 ms - Host latency: 3.0738 ms (enqueue 1.33484 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.58396 ms - Host latency: 3.23733 ms (enqueue 1.40286 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.93799 ms - Host latency: 3.59993 ms (enqueue 1.60117 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 2.96401 ms - Host latency: 3.6273 ms (enqueue 1.59546 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 3.09331 ms - Host latency: 3.7616 ms (enqueue 1.72925 ms)\n",
      "[09/24/2024-12:57:14] [I] Average on 10 runs - GPU latency: 3.09104 ms - Host latency: 3.76035 ms (enqueue 1.76252 ms)\n",
      "[09/24/2024-12:57:14] [I] \n",
      "[09/24/2024-12:57:14] [I] === Performance summary ===\n",
      "[09/24/2024-12:57:14] [I] Throughput: 266.51 qps\n",
      "[09/24/2024-12:57:14] [I] Latency: min = 2.66309 ms, max = 7.98108 ms, mean = 4.40043 ms, median = 3.45911 ms, percentile(90%) = 7.09479 ms, percentile(95%) = 7.10303 ms, percentile(99%) = 7.12042 ms\n",
      "[09/24/2024-12:57:14] [I] Enqueue Time: min = 0.798584 ms, max = 6.35986 ms, mean = 1.70634 ms, median = 1.71338 ms, percentile(90%) = 2.14563 ms, percentile(95%) = 2.23831 ms, percentile(99%) = 2.81628 ms\n",
      "[09/24/2024-12:57:14] [I] H2D Latency: min = 0.410645 ms, max = 0.499878 ms, mean = 0.424386 ms, median = 0.425583 ms, percentile(90%) = 0.43103 ms, percentile(95%) = 0.435791 ms, percentile(99%) = 0.456421 ms\n",
      "[09/24/2024-12:57:14] [I] GPU Compute Time: min = 2.01758 ms, max = 7.31494 ms, mean = 3.74385 ms, median = 2.80139 ms, percentile(90%) = 6.42896 ms, percentile(95%) = 6.43457 ms, percentile(99%) = 6.44531 ms\n",
      "[09/24/2024-12:57:14] [I] D2H Latency: min = 0.221924 ms, max = 0.254669 ms, mean = 0.232202 ms, median = 0.233093 ms, percentile(90%) = 0.240295 ms, percentile(95%) = 0.241821 ms, percentile(99%) = 0.245758 ms\n",
      "[09/24/2024-12:57:14] [I] Total Host Walltime: 3.00927 s\n",
      "[09/24/2024-12:57:14] [I] Total GPU Compute Time: 3.00257 s\n",
      "[09/24/2024-12:57:14] [W] * GPU compute time is unstable, with coefficient of variance = 48.8895%.\n",
      "[09/24/2024-12:57:14] [W]   If not already in use, locking GPU clock frequency or adding --useSpinWait may improve the stability.\n",
      "[09/24/2024-12:57:14] [I] Explanations of the performance metrics are printed in the verbose logs.\n",
      "[09/24/2024-12:57:14] [I] \n",
      "&&&& PASSED TensorRT.trtexec [TensorRT v100300] # trtexec --onnx=yolo_simplified.onnx --saveEngine=yolo.trt --fp16\n"
     ]
    }
   ],
   "source": [
    "!trtexec --onnx=yolo_simplified.onnx --saveEngine=yolo.trt --fp16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50d570df-b21e-4b75-bd43-a46121698568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/env/kunal/tensor-rt\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ceb3d8-3f25-44c9-8ce2-383a9058546a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
